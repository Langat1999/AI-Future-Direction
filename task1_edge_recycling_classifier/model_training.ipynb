{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge AI Recyclable Item Classifier - Training Notebook\n",
    "\n",
    "This notebook trains a lightweight CNN classifier for recyclable items using transfer learning with MobileNetV2.\n",
    "\n",
    "## Steps:\n",
    "1. Setup and imports\n",
    "2. Load and explore dataset\n",
    "3. Build model architecture\n",
    "4. Train the model\n",
    "5. Evaluate performance\n",
    "6. Save the model\n",
    "7. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Local modules\n",
    "sys.path.append('./src')\n",
    "import config\n",
    "import utils\n",
    "\n",
    "# Matplotlib settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "config.create_directories()\n",
    "\n",
    "# Print configuration\n",
    "config.print_config()\n",
    "\n",
    "# Get device information\n",
    "config.get_device_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Analysis\n",
    "\n",
    "**Note**: Before running the cells below, ensure you have organized your dataset as:\n",
    "```\n",
    "data/\n",
    "├── train/\n",
    "│   ├── plastic/\n",
    "│   ├── glass/\n",
    "│   ├── metal/\n",
    "│   ├── paper/\n",
    "│   └── other/\n",
    "└── val/\n",
    "    ├── plastic/\n",
    "    ├── glass/\n",
    "    ├── metal/\n",
    "    ├── paper/\n",
    "    └── other/\n",
    "```\n",
    "\n",
    "If you don't have a dataset yet, you can:\n",
    "- Use a public dataset like TrashNet or Waste Classification from Kaggle\n",
    "- Create a small sample dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training dataset\n",
    "train_stats = utils.analyze_dataset(config.TRAIN_DIR)\n",
    "\n",
    "# Analyze validation dataset\n",
    "val_stats = utils.analyze_dataset(config.VAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators with augmentation\n",
    "train_generator, val_generator, test_generator = utils.create_data_generators(\n",
    "    train_dir=config.TRAIN_DIR,\n",
    "    val_dir=config.VAL_DIR,\n",
    "    test_dir=config.TEST_DIR\n",
    ")\n",
    "\n",
    "# Verify class mappings\n",
    "print(\"\\nClass indices:\")\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Images with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a batch of training images\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(images):\n",
    "        ax.imshow(images[i])\n",
    "        class_idx = np.argmax(labels[i])\n",
    "        class_name = config.CLASS_NAMES[class_idx]\n",
    "        ax.set_title(f\"Class: {class_name}\", fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images with Augmentation', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=config.INPUT_SHAPE, num_classes=config.NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Build MobileNetV2-based classifier for edge deployment\n",
    "    \n",
    "    Architecture:\n",
    "    - MobileNetV2 base (pre-trained on ImageNet)\n",
    "    - Global Average Pooling\n",
    "    - Dropout for regularization\n",
    "    - Dense classification layer\n",
    "    \"\"\"\n",
    "    # Load pre-trained MobileNetV2\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet' if config.USE_IMAGENET_WEIGHTS else None\n",
    "    )\n",
    "    \n",
    "    # Freeze base model for transfer learning\n",
    "    base_model.trainable = not config.FREEZE_BASE_MODEL\n",
    "    \n",
    "    # Build classification head\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)  # Set training=False for inference mode\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(config.DROPOUT_RATE)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=config.FINAL_ACTIVATION)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model()\n",
    "\n",
    "# Print model summary\n",
    "utils.print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with optimizer, loss, and metrics\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=config.INITIAL_LEARNING_RATE),\n",
    "    loss=config.LOSS_FUNCTION,\n",
    "    metrics=config.METRICS + [\n",
    "        keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"✓ Model compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "# Model checkpoint - save best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=config.KERAS_MODEL_PATH,\n",
    "    monitor=config.CHECKPOINT_MONITOR,\n",
    "    mode=config.CHECKPOINT_MODE,\n",
    "    save_best_only=config.SAVE_BEST_ONLY,\n",
    "    verbose=1\n",
    ")\n",
    "callbacks.append(checkpoint_callback)\n",
    "\n",
    "# Early stopping\n",
    "if config.USE_EARLY_STOPPING:\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=config.EARLY_STOPPING_MONITOR,\n",
    "        patience=config.EARLY_STOPPING_PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(early_stopping)\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "if config.USE_REDUCE_LR:\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=config.REDUCE_LR_FACTOR,\n",
    "        patience=config.REDUCE_LR_PATIENCE,\n",
    "        min_lr=config.REDUCE_LR_MIN_LR,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(reduce_lr)\n",
    "\n",
    "print(f\"✓ {len(callbacks)} callbacks configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps per epoch\n",
    "steps_per_epoch = train_generator.samples // config.BATCH_SIZE\n",
    "validation_steps = val_generator.samples // config.BATCH_SIZE\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "print(f\"\\nStarting training for {config.EPOCHS} epochs...\\n\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=config.EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history to JSON\n",
    "utils.save_training_history(history)\n",
    "\n",
    "# Display final metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Training Metrics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_path = os.path.join(config.TRAINING_PLOTS_DIR, 'training_history.png')\n",
    "utils.plot_training_history(history, save_path=plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "val_generator.reset()\n",
    "metrics = utils.evaluate_model(model, val_generator, config.CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "val_generator.reset()\n",
    "predictions = model.predict(val_generator, verbose=1)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Plot confusion matrix\n",
    "utils.plot_confusion_matrix(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    config.CLASS_NAMES,\n",
    "    save_path=config.CONFUSION_MATRIX_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "val_generator.reset()\n",
    "utils.plot_sample_predictions(model, val_generator, num_samples=9, class_names=config.CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Keras model\n",
    "model.save(config.KERAS_MODEL_PATH)\n",
    "print(f\"✓ Keras model saved to {config.KERAS_MODEL_PATH}\")\n",
    "\n",
    "# Also save as SavedModel format (for TFLite conversion)\n",
    "model.save(config.SAVED_MODEL_DIR, save_format='tf')\n",
    "print(f\"✓ SavedModel saved to {config.SAVED_MODEL_DIR}\")\n",
    "\n",
    "# Get model size\n",
    "model_size = utils.get_model_size(config.KERAS_MODEL_PATH)\n",
    "print(f\"\\nKeras model size: {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all metrics\n",
    "final_metrics = {\n",
    "    'model_architecture': config.BASE_MODEL,\n",
    "    'input_shape': config.INPUT_SHAPE,\n",
    "    'num_classes': config.NUM_CLASSES,\n",
    "    'class_names': config.CLASS_NAMES,\n",
    "    'total_params': int(model.count_params()),\n",
    "    'model_size_mb': model_size,\n",
    "    'training': {\n",
    "        'epochs_trained': len(history.history['accuracy']),\n",
    "        'batch_size': config.BATCH_SIZE,\n",
    "        'initial_lr': config.INITIAL_LEARNING_RATE,\n",
    "        'final_train_accuracy': float(history.history['accuracy'][-1]),\n",
    "        'final_val_accuracy': float(history.history['val_accuracy'][-1]),\n",
    "        'final_train_loss': float(history.history['loss'][-1]),\n",
    "        'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "    },\n",
    "    'evaluation': metrics\n",
    "}\n",
    "\n",
    "# Save metrics\n",
    "utils.save_metrics(final_metrics)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final Validation Accuracy: {final_metrics['training']['final_val_accuracy']:.4f}\")\n",
    "print(f\"Model Size: {model_size:.2f} MB\")\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(\"1. Run tflite_conversion.ipynb to convert model to TFLite\")\n",
    "print(\"2. Test inference using src/inference.py\")\n",
    "print(\"3. Deploy to Raspberry Pi or edge device\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Optional: Fine-Tuning\n",
    "\n",
    "For better performance, you can unfreeze some layers of the base model and fine-tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to perform fine-tuning\n",
    "\n",
    "# # Unfreeze base model from a certain layer\n",
    "# base_model = model.layers[1]\n",
    "# base_model.trainable = True\n",
    "\n",
    "# # Freeze early layers, unfreeze later layers\n",
    "# for layer in base_model.layers[:config.FINE_TUNE_AT]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # Recompile with lower learning rate\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=config.FINE_TUNE_LEARNING_RATE),\n",
    "#     loss=config.LOSS_FUNCTION,\n",
    "#     metrics=config.METRICS\n",
    "# )\n",
    "\n",
    "# # Train for additional epochs\n",
    "# history_fine = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     epochs=10,\n",
    "#     validation_data=val_generator,\n",
    "#     validation_steps=validation_steps,\n",
    "#     callbacks=callbacks\n",
    "# )\n",
    "\n",
    "# # Save fine-tuned model\n",
    "# model.save(config.KERAS_MODEL_PATH.replace('.keras', '_finetuned.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Training Complete!\n",
    "\n",
    "**What we accomplished:**\n",
    "- Built a MobileNetV2-based classifier optimized for edge deployment\n",
    "- Trained with data augmentation and transfer learning\n",
    "- Achieved validation accuracy (see metrics above)\n",
    "- Saved model in Keras and SavedModel formats\n",
    "\n",
    "**Next Steps:**\n",
    "1. **Convert to TFLite**: Run `tflite_conversion.ipynb` to optimize for edge devices\n",
    "2. **Test Inference**: Use `src/inference.py` to test on new images\n",
    "3. **Deploy**: Copy TFLite model to Raspberry Pi or mobile device\n",
    "\n",
    "**Files Generated:**\n",
    "- `models/recyclable_classifier.keras` - Full Keras model\n",
    "- `models/saved_model/` - TensorFlow SavedModel format\n",
    "- `results/training_history.json` - Training metrics\n",
    "- `results/performance_metrics.json` - Evaluation results\n",
    "- `results/training_plots/` - Visualization plots\n",
    "- `results/confusion_matrix.png` - Confusion matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
